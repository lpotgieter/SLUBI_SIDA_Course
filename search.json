[
  {
    "objectID": "Day2Session1_containers.html",
    "href": "Day2Session1_containers.html",
    "title": "Containers",
    "section": "",
    "text": "There are several underlying problems within bioinformatics (and informatics in general).\n\nIt is not uncommon for people within the same team to use different operating systems (whether MacOS, Windows, or different flavours of Unix builds). Even if everyone is using a MacOS, there are still different versions that impact the way people are able to work with their machines.\nAlmost every piece of software has some sort of dependency it needs to run. Some programs might “just” need a bash shell or basic python, while others need a variety of compilers and additional libraries to function. Often, these dependencies require further dependencies to be installed. It is also not uncommon for dependencies for Program 1 to clash with the dependencies for Program 2, requiring the user to uninstall dependencies to be able to install other dependencies.\nIn bioinformatics, tools are very often not maintained after the student that wrote the software graduated, the PI moved to a different university, or the funding simply ran out. This leads to a lot of really good software not really being supported by newer operating systems, usually due to dependencies not being easily available or, as before, clashing with newer versions. This makes installing a tool one of the biggest hurdles to overcome in bioinformatics.\nYou often cannot install different versions of the same program on one computer due to conflicting names. This is particularly problematic when you want to rerun an analysis for a publication where you need to use the same software all the way through.\n\nAll of these problems mean that bioinformatics becomes less reproducible as they cannot be moved easily betweem systems (either when you upgrade your computer or want to share your pipeline with a colleague). Most of these problems can be overcome with containers.",
    "crumbs": [
      "Home",
      "Background knowledge with a bit of hands-on",
      "Containers"
    ]
  },
  {
    "objectID": "Day2Session1_containers.html#problems",
    "href": "Day2Session1_containers.html#problems",
    "title": "Containers",
    "section": "",
    "text": "There are several underlying problems within bioinformatics (and informatics in general).\n\nIt is not uncommon for people within the same team to use different operating systems (whether MacOS, Windows, or different flavours of Unix builds). Even if everyone is using a MacOS, there are still different versions that impact the way people are able to work with their machines.\nAlmost every piece of software has some sort of dependency it needs to run. Some programs might “just” need a bash shell or basic python, while others need a variety of compilers and additional libraries to function. Often, these dependencies require further dependencies to be installed. It is also not uncommon for dependencies for Program 1 to clash with the dependencies for Program 2, requiring the user to uninstall dependencies to be able to install other dependencies.\nIn bioinformatics, tools are very often not maintained after the student that wrote the software graduated, the PI moved to a different university, or the funding simply ran out. This leads to a lot of really good software not really being supported by newer operating systems, usually due to dependencies not being easily available or, as before, clashing with newer versions. This makes installing a tool one of the biggest hurdles to overcome in bioinformatics.\nYou often cannot install different versions of the same program on one computer due to conflicting names. This is particularly problematic when you want to rerun an analysis for a publication where you need to use the same software all the way through.\n\nAll of these problems mean that bioinformatics becomes less reproducible as they cannot be moved easily betweem systems (either when you upgrade your computer or want to share your pipeline with a colleague). Most of these problems can be overcome with containers.",
    "crumbs": [
      "Home",
      "Background knowledge with a bit of hands-on",
      "Containers"
    ]
  },
  {
    "objectID": "Day2Session1_containers.html#containers",
    "href": "Day2Session1_containers.html#containers",
    "title": "Containers",
    "section": "Containers",
    "text": "Containers\n\nWhat are containers?\nContainers are stand-alone pieces of software that require a container management tool to run. Containers contain an operating system, all dependencies, and software in an isolates environment. Container management tools can be run on all operating systems, and since the container has the operating system within it, it will run the same in all environments. Containers are also immutable, so it is stable over time.\n\n\nRunning Containers\nThere are several programs that can be used to run containers. Docker, Appptainer, and Podman are the most commonly used platforms. They all have their pros and cons. If you are using a Windows machine that only you are using, then Docker is likely the least complex tool to install. On multi-user systems like a server, Apptainer is the best tool for the job. For this tutorial and the rest of the course, we will use Apptainer commands. There are small syntax changes between bash and powershell commands, but they are very similar.\n\n\nDownloading Containers\nThere are several repositories for people to upload containers that they have built. dockerhub and Seqera are two commonly used platforms for downloading containers. You are able to run containers from dockerhub on Apptainer without any problems.\n\ndockerhub Tutorial\nOn the dockerhub landing page, you have a search bar, and some login options. You do not need to create an account to access the containers on dockerhub.\n\n\n\ndockerhub landing page\n\n\nFor these tutorials, we’ll search VCFtools, a commonly used software for VCF manipulation and querying. The results of the search give us several different containers with the same name.\n\n\n\nRegistry search\n\n\nYou can see who built the container, how many times it has been pulled, when it was updated (here updated means different versions of the container being uploaded), and how many people have starred it. It is usually a good rule of thumb to use the most popular containers from users that have uploaded a lot of containers. The biocontainers and pegi3s profiles have builds for a lot of tools, and they are built really well!\nIf we click on the image from biocontainers we get to a typical dockerhub image landing page:\n\n\n\nVCFtools page\n\n\nThere is information on the frequency of the container being pulled, as well as a pull command. This command is for docker, so we need to modify it for Apptainer.\napptainer pull vcftools_0.1.16-1.sif docker://biocontainers/vcftools\nThis command has several parts to it:\n\napptainer calls on the Apptainer software to run\npull tells Apptainer which function to use. In this case, we want it to go fetch something from a repository\nvcftools_0.1.16-1.sif is the name of the container on our local machine. We could call it I_Love_Dogs but that is not very informative at all. Your collaborator won’t know what it means, and you certainly won’t know what it means in 6 months from now! It is also good practice to put the version number in your image name in case you want to have several versions at the same time, and you need to tell them apart.\ndocker:// is the registry you are pulling from. There are several different registreis, but we are only going to show 2 during this course. (You will see another one in the Seqera tutorial)\nbiocontainers/vcftools is the profile/repository and container you are pulling\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nFile format extensions like .txt and .sif are really only important for us. However, it is good practice to append your files with appropriate extensions to ensure that you follow good data management practices\n\n\n\nIf you are interested in a different version than the current version, there are other versions under the tags tab:\n\n\n\nContainer versions\n\n\nIf you wanted to download another version of the container, you simply copy the command shown on the right side, and alter the syntax, for example\napptainer pull vcftools0.1.14.sif docker://biocontainers/vcftools:v0.1.14_cv2\n\n\nSeqera Tutorial\nThe Seqera landing page is a bit different from the dockerhub landing page, and it works a bit differently from dockerhub. dockerhub hosts container images that users have uploaded, while Seqera builds containers as you request them. They use bioconda, conda-forge, and pypi libraries to build their containers with Wave. The advantage is that you can include several different softwares in your container image at once. The disadvantage is that you are limited to software hosted on the aforementioned repositories. Usually this isn’t a problem, but sometimes you want to use something that isn’t hosted there.\n\n\n\nSeqera containers landing page\n\n\nWhen you pull an image from Seqera and want to run it with Apptainer, you need to remember to change the container setting from Docker to Singularity\n\n\n\nSelecting Singularity\n\n\nSince Seqera builds containers on-demand, sometimes you have to wait for the container to finish compiling. You can see that it is still building the container from the fetching container comment. Don’t try to pull it when it is still building!\n\n\n\nWaiting to build\n\n\nWhen the container is built, you can copy the text and pull the container to your system\n\n\n\nReady to download\n\n\napptainer pull vcftools_0.1.17.sif oras://community.wave.seqera.io/library/vcftools:0.1.17--b541aa8d9f9213f9\nHere we use oras:// instead of docker:// as we are pulling from the oras registry. We are also pulling a different version from Seqera, so the name of the container is different.\n\n\n\nRunning Containers\nOnce you have the container on your local machine, you want to be able to use it. Apptainer can be used to enter the container and run as if you had the exact same operating system as the person who built it, or it can run the software inside the container from outside of the container.\nThere are 2 different ways to use a container: run and exec. The apptainer run command launches the container and first runs the %runscript for the container if one is defined, and then runs your command (we will cover %runscript in the Building Containers section). The apptainer exec command will not run the %runscript even if one is defined. It is a small, fiddly detail that might be applicable if you use other people’s containers. After calling Apptainer and the run or exec commands, you can use your software as you usually would\napptainer exec vcftools_0.1.17.sif vcftools --version\nThis command runs your vcftools_0.1.17.sif container, calls on the program vcftools that is within the container, and will show you the version. If you had installed VCFtools locally, you would have just used\nvcftools --version\n\n\n\n\n\n\nImportant\n\n\n\nPlease remember that VCFtools is just an example. If you want to run any other tool everything after apptainer run or apptainer exec has to substitute the name of your container and the run commands for that particular tool!\n\n\n\n\nBuilding Containers\nIf the software you would like to use is not packaged into a container by anyone else, you might want to build it yourself. For this, we are just going to show a very simple example. Building containers from scratch is a computationally intensive task. You build containers from a definition file with the extension .def\nHere we are going to build a container with a cow telling us the date. Save this in a file called lolcow.def\nBootstrap: docker\nFrom: ubuntu:20.04\n\n%post\n    apt-get -y update\n    apt-get -y install cowsay lolcat fortune\n\n%environment\n    export LC_ALL=C\n    export PATH=/usr/games:$PATH\n\n%runscript\n    date | cowsay | lolcat    \n\nThere are several components to this definition file.\n\nYou can set the operating system you want in the container, in this case Ubuntu 20.04\n%post section is where you update the OS from its base state, install dependencies and so on\n%environment is where you export paths and modify the environment\n%runscript is the script that will run when you use apptainer run container.sif. If you don’t include a runscript, then nothing will happen when you try to run it without any commands. You could build this container without anything in the %runscript section, and use apptainer run container.sif date | cowsay | lolcat to get the same output.\n\napptainer build lolcow.sif lolcow.def\nYou’ll get a lot of output on the status of the build, ending of\nINFO:    Adding environment to container\nINFO:    Adding runscript\nINFO:    Creating SIF file...\nINFO:    Build complete: lolcow.sif\nWe can now run our new container with\napptainer run lolcow.sif\n\n\n\nBoring cow\n\n\n\n\n\n\n\n\nNote\n\n\n\nTry removing the %runscript, build it again, and see what happens\n\n\nBootstrap: docker\nFrom: ubuntu:20.04\n\n%post\n    apt-get -y update\n    apt-get -y install cowsay lolcat fortune\n\n%environment\n    export LC_ALL=C\n    export PATH=/usr/games:$PATH\n\n%runscript\n    fortune | cowsay | lolcat    \n\nIf we use the same definition file as before, but substitute date for fortune in the runscript and build the container, we now get a philosophical cow with a dark sense of humour\n\n\n\nFun cow\n\n\n\n\n\nInspirational cow\n\n\nTo show the difference between the run and exec commands, we can use the same container with fortune in the runscript and run\napptainer run lolcow.sif date|cowsay\nand\napptainer exec lolcow.sif date|cowsay\nThe run command gives us a philosophical cow while exec gives us our boring cow again",
    "crumbs": [
      "Home",
      "Background knowledge with a bit of hands-on",
      "Containers"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This course is a hosted by the Swedish Agricultural University’s Bioinformatics Infrastructure (SLUBI) team. In this course we hope to give you information on how to use reproducible bioinformatics pipelines, report results in a streamlined manner, and implement the system in your own research groups.\nThis course is funded by SIDA and is hosted in Alnarp, Sweden on the 25th-29th August 2025"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SLUBI SIDA Course",
    "section": "",
    "text": "We are pleased to have this course with you! Our main aim with this course is to share how we use bioinformatics tools in a reproducible and scalable way. We will showcase the use of environments, containers, and established pipelines so that you can run these analyses on any operating system, as well as on systems that are not high performance computing clusters.\nThe website will remain active after the course so that you have access to the material, and we encourage you to share these resources with your students and other researchers that might benefit from this!\n\nProgram\n\n\nDay\nSession\n\n\n\n\nMonday\nIntroduction to nf-core and Nextflow\n\n\n\nIntroduction to Linux\n\n\n\nIntroduction to Environments\n\n\nTuesday\nIntroduction to Containers\n\n\n\nSetting up and running a Nextflow Pipeline (with us)\n\n\n\nSetting up and running a Nextflow Pipeline (by yourself)\n\n\nWednesday\nData Management and Reproducible Research\n\n\n\nIntroduction to Markdown and Quarto\n\n\n\nGitHub\n\n\n\nHow do Nextflow Pipelines Work?\n\n\nThursday\nNextflow Results\n\n\n\nUsing Containers Outside of Nextflow\n\n\n\nUsing R and Other Languages in Quarto\n\n\nFriday\nWhat are your needs? How can you implement this in your own institutions?\n\n\n\nFriday is an emptier day in case we run out of time for something, or if there is something that you would like to learn more about.\nEvery day will end with a feedback session, and we hope that you will tell us what you like, what isn’t working for you, and what you would like to see more of.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "Day3Session2_quarto.html",
    "href": "Day3Session2_quarto.html",
    "title": "Introduction to Markdown and Quarto",
    "section": "",
    "text": "Markdown is a lightweight markup language for text editing. All of the documents you have seen in this course have been formatted with markdown. The platform this course website has been built on is called Quarto and implements markdown. In this section, we’ll look at some of the post commonly used markdown syntax, using Quarto to create lab notebooks, presentations, automate analyses, and host websites like this one.\nRecently, a lot of open-source books like R for Data Science and Python for Data Science have been created with Markdown using Quarto. The code for these books have also been publicly released.\n\n\n\n\n\n\nImportant\n\n\n\nPlease bookmark these books for your students! They are excellent resources!",
    "crumbs": [
      "Home",
      "Data management",
      "Introduction to Markdown and Quarto"
    ]
  },
  {
    "objectID": "Day3Session2_quarto.html#introduction",
    "href": "Day3Session2_quarto.html#introduction",
    "title": "Introduction to Markdown and Quarto",
    "section": "",
    "text": "Markdown is a lightweight markup language for text editing. All of the documents you have seen in this course have been formatted with markdown. The platform this course website has been built on is called Quarto and implements markdown. In this section, we’ll look at some of the post commonly used markdown syntax, using Quarto to create lab notebooks, presentations, automate analyses, and host websites like this one.\nRecently, a lot of open-source books like R for Data Science and Python for Data Science have been created with Markdown using Quarto. The code for these books have also been publicly released.\n\n\n\n\n\n\nImportant\n\n\n\nPlease bookmark these books for your students! They are excellent resources!",
    "crumbs": [
      "Home",
      "Data management",
      "Introduction to Markdown and Quarto"
    ]
  },
  {
    "objectID": "Day3Session2_quarto.html#markdown-syntax",
    "href": "Day3Session2_quarto.html#markdown-syntax",
    "title": "Introduction to Markdown and Quarto",
    "section": "Markdown Syntax",
    "text": "Markdown Syntax\nThere are plenty of really great cheatsheets like this one from Markdown Guide as well as this one. We’ll go through some of these details with you live rather than copying and pasting really good tutorials here.",
    "crumbs": [
      "Home",
      "Data management",
      "Introduction to Markdown and Quarto"
    ]
  },
  {
    "objectID": "Day3Session2_quarto.html#using-markdown",
    "href": "Day3Session2_quarto.html#using-markdown",
    "title": "Introduction to Markdown and Quarto",
    "section": "Using Markdown",
    "text": "Using Markdown\nThere are many different platforms that use Markdown syntax in text editing. At SLUBI, we have a strong preference towards Visual Studio Code or its open-source alternative, VSCodium. To use all of the features, you need to install the Markdown extension.\nTo access to Extensions, either navigate with shortcuts (these are operating system depdenent and can be set by users, so we won’t go into that, but feel free to explore), from the View dropdown menu, or from the Extensions tab on the left.\n\n\n\nExtensions from View\n\n\n\n\n\nExtensions from the shortcut\n\n\nIn the search bar, you can search for general Markdown viewers and install them. For this course, we will use Quarto. Install that extension. Please also note the verified tick.\n\n\n\nQuarto extension to install\n\n\nThe Markdown All in One extension is also an interesting case to look at. It has a lot of downloads despite not being verified by an organisation. In general, be wary when installing extensions. Opt for ones that are installed often, as this one is. If possible, try to use verified extensions. In the age of information security we live in, it is becoming more important to use trusted content than whatever you find on the internet.",
    "crumbs": [
      "Home",
      "Data management",
      "Introduction to Markdown and Quarto"
    ]
  },
  {
    "objectID": "Day3Session2_quarto.html#quarto",
    "href": "Day3Session2_quarto.html#quarto",
    "title": "Introduction to Markdown and Quarto",
    "section": "Quarto",
    "text": "Quarto\nQuarto is an open-source technical and scientific reporting and publishing system.\n\n\n\nQuarto landing page\n\n\n\nInstalling Quarto on your Machine\nWe have already installed the extension that allows us to use a bunch of really cool features in VSCode with Quarto, but we need to have the backend installed on our machines as well. To install the program, you will click on the Get Started link on the homepage, download the program that’s suited to your operating system, and install it. The Guide link here also takes you to really easy tutorials on how to set up a variety of other uses of Quarto that we simply don’t have time for in this course.\n\n\n\n\n\n\nImportant\n\n\n\nAll instructions for creating, editing, previewing, and rendering projects will be shown in VSCode and it will not be specified over and over\n\n\n\n\nCreating a Project\nUnder the previously shown View option, navigate to the Command Palette. A dropdown menu at the top will start with a &gt;. Type quarto and a list of functions will be shown. The order will be different based on what you’ve used and what you’ve used most recently.\n\n\n\nQuarto functions\n\n\nWe will Create a project and create a Website for the purpose of this course.\n\n\n\nCreating a Project\n\n\n\nStructure of a Project\nAll Quarto projects have a YAML file with information about the project called _quarto.yml as well as an index.qmd file. The landing page of your website is the index.qmd file, while the _quarto.yml file contains all of the visual aspects of your website. We’ll spend a bit of time looking at the design of our course website so that you can see how it looks behind the scenes. Hopefully, with a website you know as well as you do by now, this will make things a lot more tangible!\n\n\n\n\n\n\nNote\n\n\n\n\n\nFun fact: YAML stands for “yet another markup language”\n\n\n\n\n\n\nAdding Files and Figures\nOften, we don’t just need a landing page like the index.qmd file, but we want different pages, as we have here. You can add blank documents with the .qmd extenstion. It is important for each file to have a title section so that it can be displayed properly and linked with your other pages. Update the _quarto.yml file to include this page in your table of contents or navigation bar (depending on what you opted to use), or simply link to the file with a hyperlink as we have done on our landing page\n\n\n\n\n\n\nTip\n\n\n\nRemeber to give your files a good name with no spaces in them. Also remember to add the .qmd extension\n\n\nTo add external figures to your document as we have done here with screenshots, you can simply link to the figure by its relative path, as described here.\n\n\n\n\n\n\nTip\n\n\n\nIt is good practice to have your images in a folder inside of your Quarto project in case Future You forgets that a figure is linked to a document and you move the folder containing all of your photos, for example. It also makes it much easier to put everything into a repository on GitHub to launch your site\n\n\n\n\nAdding Analyses\nQuarto is really good at implementing other programming languages within it. You can use R within it seamlessly. There is support for a large number of other programming languages within Quarto, but this course is only going to showcase the use of R.\n\n\n\n\n\n\nImportant\n\n\n\nYou will have to install the R and R syntax extensions for this to work in VSCode\n\n\n\npacman::p_load(tidyverse, palmerpenguins)\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point(mapping = aes(color = species, shape = species)) +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nIf you have analyses that you have to repeat across several projects, these documents can be shared to create uniformity among your produced results, and your students do not need to reinvent the wheel. With several pages being supported in a single Quarto project, you also reduce the potential messiness that is introduced whenever you onboard a new student.\n\n\nViewing the Project\n\nPreviewing\nAs you go along, you might be interested in seeing what your pages look like. In the terminal, type\nquarto preview\nor simply click the preview button in VSCode and a side by side preview will open where you can click through your indexed pages.\n\n\n\nVSCode Preview function\n\n\n\n\nDifferent Views\nFrom the Command Palette, you can select whether you would like to view your document in source mode or in visual mode. The difference is mostly that you can interact with the document in the way it will be rendered in visual mode. For some people, visual mode is a lot more intuative, and there is no right or wrong way to interact with your documents.\n\n\n\nPublishing and Sharing the Project\nWith Quarto, you can render to HTML, Word, and PDF formats. To render individual files into PDF, add the information from this Quarto guide into the header of your document.\n---\ntitle: \"My document\"\nformat:\n  pdf:\n    toc: true\n    number-sections: true\n    colorlinks: true\n---\nYou will have to install a recent distribution of TeX for this via your terminal\nquarto install tinytex\nFor this course, we are simply going to render our documents into HTML format. In the next section, we will cover how to host Quarto pages on GitHub.",
    "crumbs": [
      "Home",
      "Data management",
      "Introduction to Markdown and Quarto"
    ]
  },
  {
    "objectID": "Day1Session2_linux.html",
    "href": "Day1Session2_linux.html",
    "title": "A Brief Introduction to Linux",
    "section": "",
    "text": "Unix-like operating systems are built under the model of free and open-source development and distribution. They often come with a graphical user interface (GUI) and can be run from the command line (CLI) or terminal. The CLI is a text-based interface that works exactly the same way as you would use your mouse, but you use words. It can be intimidating at first, but once you have mastered the basics, it’s really not different than using your mouse!\nIt is important to know how to use the terminal as all servers, and most bioinformatics tools do not have a GUI and rely on the use of the terminal.\n\n\n\n\n\n\nWarning\n\n\n\nMacOS and Linux, and Windows have significant differences in their syntax. Where we do things locally, we will point out some of the differences, but for the most part, we will provide Windows users with a local Linux platform so that this course can run as smoothly as possible\n\n\nFor this course, we do not expect you to be masters of Linux, but we will need some knowledge of how to find files, and some other basic Linux commands.",
    "crumbs": [
      "Home",
      "Background knowledge with a bit of hands-on",
      "A Brief Introduction to Linux"
    ]
  },
  {
    "objectID": "Day1Session2_linux.html#introduction",
    "href": "Day1Session2_linux.html#introduction",
    "title": "A Brief Introduction to Linux",
    "section": "",
    "text": "Unix-like operating systems are built under the model of free and open-source development and distribution. They often come with a graphical user interface (GUI) and can be run from the command line (CLI) or terminal. The CLI is a text-based interface that works exactly the same way as you would use your mouse, but you use words. It can be intimidating at first, but once you have mastered the basics, it’s really not different than using your mouse!\nIt is important to know how to use the terminal as all servers, and most bioinformatics tools do not have a GUI and rely on the use of the terminal.\n\n\n\n\n\n\nWarning\n\n\n\nMacOS and Linux, and Windows have significant differences in their syntax. Where we do things locally, we will point out some of the differences, but for the most part, we will provide Windows users with a local Linux platform so that this course can run as smoothly as possible\n\n\nFor this course, we do not expect you to be masters of Linux, but we will need some knowledge of how to find files, and some other basic Linux commands.",
    "crumbs": [
      "Home",
      "Background knowledge with a bit of hands-on",
      "A Brief Introduction to Linux"
    ]
  },
  {
    "objectID": "Day1Session2_linux.html#filesystem-architecture",
    "href": "Day1Session2_linux.html#filesystem-architecture",
    "title": "A Brief Introduction to Linux",
    "section": "Filesystem Architecture",
    "text": "Filesystem Architecture\nLinux uses a hierarchical filesystem, similar to Windows and Mac. In this figure from TecAdmin, there is a representation of this.\n\n\n\nFilesystem\n\n\nWe can see here that the root or / folder is at the top of the hierarchy, with all other folders, like home/ and var/ inside of it.\n\n\n\n\n\n\nNote\n\n\n\n\n\nWe use / at the end of a folder name to show that it is a folder.\n\n\n\nThere are two different ways for us to know where our file is within the operating system. The first is the absolute path and the second is the relative path. The absolute path gives us information that is true anywhere on your operating system. Whether your terminal is open in /usr/bin/something/ or /var/tmp/, a file will always be located at /usr/Documents/sequence.fasta as it is the true or absolute location. The relative path, as the name suggests, is relative to where you currently are on the file tree. If your terminal is open in /usr/Documents/paper/figures/, the file from before, sequence.fasta will be two folders up from where you are. If you were in /var/bin/something/ it would three folder up, one to the side, and two folders down.\n\n\n\n\n\n\nTip\n\n\n\n\n\nIt is often good practice to use absolute paths when you set pipelines up to run- this way, your programs know where to go looking for the files they’re supposed to work on",
    "crumbs": [
      "Home",
      "Background knowledge with a bit of hands-on",
      "A Brief Introduction to Linux"
    ]
  },
  {
    "objectID": "Day1Session2_linux.html#connecting-to-a-server",
    "href": "Day1Session2_linux.html#connecting-to-a-server",
    "title": "A Brief Introduction to Linux",
    "section": "Connecting to a Server",
    "text": "Connecting to a Server\nThere are many different ways you can connect to a server with SSH. At SLUBI, we have a strong preference towards Visual Studio Code or its open-source alternative, VSCodium. It provides a graphical user interface where you can create, edit, and view files, and see the file system.\nTo be able to connect to a server, you need to install an extension called Remote-SSH from the extensions market place.\n\n\n\nExtensions from View\n\n\n\n\n\nExtensions from the shortcut\n\n\nNow we need to add a host to our list of known hosts. There are several ways of doing this, and all ways lead to establishing a connection.\n\nUnder the previously shown View option, navigate to the Command Palette. A dropdown menu at the top will start with a &gt;. Type Remote-SSH and select add new host. Here we will input our credentials. This will populate a file in a hidden folder, .ssh in your local home directories called known_hosts.\nYou can also write all of these lines manually. This way, you can also specify SSH keys that may be needed to log on to particular servers. We won’t be covering that in this course, though.\n\nAfter a host has been added, you can connect to it. You can do this either through the Command Palette, or through the small blue backwards and forwards arrows in the bottom left corner of VSCode. You will receive a list of known hosts that you can connect to. If you need to connect with a password, a password prompt will be shown.\nOnce connected, you can open the file manager on the left.\nFor privacy concerns, we will share the exact commands locally in the room.\n\n\n\n\n\n\nImportant\n\n\n\nRemeber to only open either your home directories or the folder for your projects with the file manager. If you try to open folders that are too large, you will cause VSCode to crash (and you may cause significant problems for your system administrator!)",
    "crumbs": [
      "Home",
      "Background knowledge with a bit of hands-on",
      "A Brief Introduction to Linux"
    ]
  },
  {
    "objectID": "Day1Session2_linux.html#navigating-with-the-terminal",
    "href": "Day1Session2_linux.html#navigating-with-the-terminal",
    "title": "A Brief Introduction to Linux",
    "section": "Navigating with the terminal",
    "text": "Navigating with the terminal\nFor this part of the session, we will do some hands-on practice! For this, we will open a terminal. You can do this through the Command Palette by using the View: Toggle Terminal function, or clicking the box with a dark bottom half and an empty top half in the top right corner of VSCode.\n\n\n\n\n\n\nNote\n\n\n\n\n\nFor Windows Users If you are using a Windows operating system, you can install the free Home edition of MobaXterm when your access to this server is removed if you want to continue practicing your Linux skills.\nTo use MobaXterm as a Linux shell, click on New Session and select a bash shell. There will probably be a prompt that you have to installl an extension. Click on the link it will provide, or copy the extension it needs and search it on Google (or your preferred search engine) and install it. Then try starting a new session again.\n\n\n\nTo see where we currently are in the filesystem, we use the present working directory command. This will give us the absolute path of the directory that our terminal open in.\npwd\nTo see the files that are currently in the directory we use the list command.\nls\nTo make a directory, we use the make directory command, followed by the name we would like our directory to have. Here we will make a directory called sida_training.\nmkdir sida_training\n\n\n\n\n\n\nTip\n\n\n\n\n\nWhen we give files and folders names, we don’t use spaces or special characters. It makes it really difficult to access files. We can use different ways to name our files and folders 1. youcanbechaoticandusenothing 2. YouCanUseCapitalLetters 3. you_can_use_underscores 4. you-can-use-dashes The most important thing is to be consistent with what you use, and to use descriptive names that are not too long. Future you will thank past you!\n\n\n\nTo enter the sida_training directory, we will use the change directory command.\ncd sida_training\nWe can use the pwd command again just to make sure that we are indeed in the right folder.\nTo go back to the folder we were in previously, we can use a shortcut rather than the absolute path.\ncd ..\n\n\n\n\n\n\nTip\n\n\n\n\n\nThere are no limits to the amount of directories you can go back (provided they are in your filesystem). If you wanted to go up 3 directories, you’d use\ncd ../../..\n\n\n\nTo delete files and folder you use the remove command. If you want to remove a folder, you need a recursive flag.\nrm -r sida_training\nIf we had a file to look at, we could use the less command. In the interface, we press q to quit.\nless filename\nWith these Linux basics, you will certainly be able to follow our course. If you would like to learn more, Data Carpentry and Software Carpentry have excellent tutorials on using the terminal in more detail, and we can only recommend them!",
    "crumbs": [
      "Home",
      "Background knowledge with a bit of hands-on",
      "A Brief Introduction to Linux"
    ]
  }
]
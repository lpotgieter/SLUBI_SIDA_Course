[
  {
    "objectID": "Day1Session2_linux.html",
    "href": "Day1Session2_linux.html",
    "title": "A Brief Introduction to Linux",
    "section": "",
    "text": "Unix-like operating systems are built under the model of free and open-source development and distribution. They often come with a graphical user interface (GUI) and can be run from the command line (CLI) or terminal. The CLI is a text-based interface that works exactly the same way as you would use your mouse, but you use words. It can be intimidating at first, but once you have mastered the basics, it’s really not different than using your mouse!\nIt is important to know how to use the terminal as all servers, and most bioinformatics tools do not have a GUI and rely on the use of the terminal.\n\n\n\n\n\n\nWarning\n\n\n\nMacOS and Linux, and Windows have significant differences in their syntax. Where we do things locally, we will point out some of the differences, but for the most part, we will provide Windows users with a local Linux platform so that this course can run as smoothly as possible\n\n\nFor this course, we do not expect you to be masters of Linux, but we will need some knowledge of how to find files, and some other basic Linux commands.",
    "crumbs": [
      "Home",
      "Background knowledge with a bit of hands-on",
      "A Brief Introduction to Linux"
    ]
  },
  {
    "objectID": "Day1Session2_linux.html#introduction",
    "href": "Day1Session2_linux.html#introduction",
    "title": "A Brief Introduction to Linux",
    "section": "",
    "text": "Unix-like operating systems are built under the model of free and open-source development and distribution. They often come with a graphical user interface (GUI) and can be run from the command line (CLI) or terminal. The CLI is a text-based interface that works exactly the same way as you would use your mouse, but you use words. It can be intimidating at first, but once you have mastered the basics, it’s really not different than using your mouse!\nIt is important to know how to use the terminal as all servers, and most bioinformatics tools do not have a GUI and rely on the use of the terminal.\n\n\n\n\n\n\nWarning\n\n\n\nMacOS and Linux, and Windows have significant differences in their syntax. Where we do things locally, we will point out some of the differences, but for the most part, we will provide Windows users with a local Linux platform so that this course can run as smoothly as possible\n\n\nFor this course, we do not expect you to be masters of Linux, but we will need some knowledge of how to find files, and some other basic Linux commands.",
    "crumbs": [
      "Home",
      "Background knowledge with a bit of hands-on",
      "A Brief Introduction to Linux"
    ]
  },
  {
    "objectID": "Day1Session2_linux.html#filesystem-architecture",
    "href": "Day1Session2_linux.html#filesystem-architecture",
    "title": "A Brief Introduction to Linux",
    "section": "Filesystem Architecture",
    "text": "Filesystem Architecture\nLinux uses a hierarchical filesystem, similar to Windows and Mac. In this figure from TecAdmin, there is a representation of this.\n\n\n\nFilesystem\n\n\nWe can see here that the root or / folder is at the top of the hierarchy, with all other folders, like home/ and var/ inside of it.\n\n\n\n\n\n\nNote\n\n\n\n\n\nWe use / at the end of a folder name to show that it is a folder.\n\n\n\nThere are two different ways for us to know where our file is within the operating system. The first is the absolute path and the second is the relative path. The absolute path gives us information that is true anywhere on your operating system. Whether your terminal is open in /usr/bin/something/ or /var/tmp/, a file will always be located at /usr/Documents/sequence.fasta as it is the true or absolute location. The relative path, as the name suggests, is relative to where you currently are on the file tree. If your terminal is open in /usr/Documents/paper/figures/, the file from before, sequence.fasta will be two folders up from where you are. If you were in /var/bin/something/ it would three folder up, one to the side, and two folders down.\n\n\n\n\n\n\nTip\n\n\n\n\n\nIt is often good practice to use absolute paths when you set pipelines up to run- this way, your programs know where to go looking for the files they’re supposed to work on",
    "crumbs": [
      "Home",
      "Background knowledge with a bit of hands-on",
      "A Brief Introduction to Linux"
    ]
  },
  {
    "objectID": "Day1Session2_linux.html#navigating-with-the-terminal",
    "href": "Day1Session2_linux.html#navigating-with-the-terminal",
    "title": "A Brief Introduction to Linux",
    "section": "Navigating with the terminal",
    "text": "Navigating with the terminal\nFor this part of the session, we will do some hands-on practice, so please open a terminal\n\n\n\n\n\n\nFor Windows Users\n\n\n\n\n\nIf you are using a Windows operating system, please install the free Home edition of MobaXterm.\nTo use MobaXterm as a Linux shell, click on New Session and select a bash shell. There will probably be a prompt that you have to installl an extension. Click on the link it will provide, or copy the extension it needs and search it on Google (or your preferred search engine) and install it. Then try starting a new session again.\n\n\n\nTo see where we currently are in the filesystem, we use the present working directory command. This will give us the absolute path of the directory that our terminal open in.\npwd\nTo see the files that are currently in the directory we use the list command.\nls\nTo make a directory, we use the make directory command, followed by the name we would like our directory to have. Here we will make a directory called sida_training.\nmkdir sida_training\n\n\n\n\n\n\nTip\n\n\n\n\n\nWhen we give files and folders names, we don’t use spaces or special characters. It makes it really difficult to access files. We can use different ways to name our files and folders 1. youcanbechaoticandusenothing 2. YouCanUseCapitalLetters 3. you_can_use_underscores 4. you-can-use-dashes The most important thing is to be consistent with what you use, and to use descriptive names that are not too long. Future you will thank past you!\n\n\n\nTo enter the sida_training directory, we will use the change directory command.\ncd sida_training\nWe can use the pwd command again just to make sure that we are indeed in the right folder.\nTo go back to the folder we were in previously, we can use a shortcut rather than the absolute path.\ncd ..\n\n\n\n\n\n\nTip\n\n\n\n\n\nThere are no limits to the amount of directories you can go back (provided they are in your filesystem). If you wanted to go up 3 directories, you’d use\ncd ../../..\n\n\n\nTo delete files and folder you use the remove command. If you want to remove a folder, you need a recursive flag.\nrm -r sida_training\nIf we had a file to look at, we could use the less command. In the interface, we press q to quit.\nless filename\nWith these Linux basics, you will certainly be able to follow our course. If you would like to learn more, Data Carpentry and Software Carpentry have excellent tutorials on using the terminal in more detail, and we can only recommend them!",
    "crumbs": [
      "Home",
      "Background knowledge with a bit of hands-on",
      "A Brief Introduction to Linux"
    ]
  },
  {
    "objectID": "Day2Session1_containers.html",
    "href": "Day2Session1_containers.html",
    "title": "Containers",
    "section": "",
    "text": "There are several underlying problems within bioinformatics (and informatics in general). 1. It is not uncommon for people within the same team to use different operating systems (whether MacOS, Windows, or different flavours of Unix builds). Even if everyone is using a MacOS, there are still different versions that impact the way people are able to work with their machines. 2. Almost every piece of software has some sort of dependency it needs to run. Some programs might “just” need a bash shell or basic python, while others need a variety of compilers and additional libraries to function. Often, these dependencies require further dependencies to be installed. It is also not uncommon for dependencies for Program 1 to clash with the dependencies for Program 2, requiring the user to uninstall dependencies to be able to install other dependencies. 3. In bioinformatics, tools are very often not maintained after the student that wrote the software graduated, the PI moved to a different university, or the funding simply ran out. This leads to a lot of really good software not really being supported by newer operating systems, usually due to dependencies not being easily available or, as before, clashing with newer versions. This makes installing a tool one of the biggest hurdles to overcome in bioinformatics. 4. You often cannot install different versions of the same program on one computer due to conflicting names. This is particularly problematic when you want to rerun an analysis for a publication where you need to use the same software all the way through.\nAll of these problems mean that bioinformatics becomes less reproducible as they cannot be moved easily betweem systems (either when you upgrade your computer or want to share your pipeline with a colleague). Most of these problems can be overcome with containers.",
    "crumbs": [
      "Home",
      "Background knowledge with a bit of hands-on",
      "Containers"
    ]
  },
  {
    "objectID": "Day2Session1_containers.html#problems",
    "href": "Day2Session1_containers.html#problems",
    "title": "Containers",
    "section": "",
    "text": "There are several underlying problems within bioinformatics (and informatics in general). 1. It is not uncommon for people within the same team to use different operating systems (whether MacOS, Windows, or different flavours of Unix builds). Even if everyone is using a MacOS, there are still different versions that impact the way people are able to work with their machines. 2. Almost every piece of software has some sort of dependency it needs to run. Some programs might “just” need a bash shell or basic python, while others need a variety of compilers and additional libraries to function. Often, these dependencies require further dependencies to be installed. It is also not uncommon for dependencies for Program 1 to clash with the dependencies for Program 2, requiring the user to uninstall dependencies to be able to install other dependencies. 3. In bioinformatics, tools are very often not maintained after the student that wrote the software graduated, the PI moved to a different university, or the funding simply ran out. This leads to a lot of really good software not really being supported by newer operating systems, usually due to dependencies not being easily available or, as before, clashing with newer versions. This makes installing a tool one of the biggest hurdles to overcome in bioinformatics. 4. You often cannot install different versions of the same program on one computer due to conflicting names. This is particularly problematic when you want to rerun an analysis for a publication where you need to use the same software all the way through.\nAll of these problems mean that bioinformatics becomes less reproducible as they cannot be moved easily betweem systems (either when you upgrade your computer or want to share your pipeline with a colleague). Most of these problems can be overcome with containers.",
    "crumbs": [
      "Home",
      "Background knowledge with a bit of hands-on",
      "Containers"
    ]
  },
  {
    "objectID": "Day2Session1_containers.html#containers",
    "href": "Day2Session1_containers.html#containers",
    "title": "Containers",
    "section": "Containers",
    "text": "Containers\n\nWhat are containers?\nContainers are stand-alone pieces of software that require a container management tool to run. Containers contain an operating system, all dependencies, and software in an isolates environment. Container management tools can be run on all operating systems, and since the container has the operating system within it, it will run the same in all environments. Containers are also immutable, so it is stable over time.\n\n\nRunning Containers\nThere are several programs that can be used to run containers. Docker, Appptainer, and Podman are the most commonly used platforms. They all have their pros and cons. If you are using a Windows machine that only you are using, then Docker is likely the least complex tool to install. On multi-user systems like a server, Apptainer is the best tool for the job. For this tutorial and the rest of the course, we will use Apptainer commands. There are small syntax changes between bash and powershell commands, but they are very similar.\n\n\nDownloading Containers\nThere are several repositories for people to upload containers that they have built. dockerhub and Seqera are two commonly used platforms for downloading containers. You are able to run containers from dockerhub on Apptainer without any problems.\n\ndockerhub Tutorial\nOn the dockerhub landing page, you have a search bar, and some login options. You do not need to create an account to access the containers on dockerhub.\n\n\n\nFilesystem\n\n\nFor these tutorials, we’ll search VCFtools, a commonly used software for VCF manipulation and querying. The results of the search give us several different containers with the same name.\n\n\n\nFilesystem\n\n\nYou can see who built the container, how many times it has been pulled, when it was updated (here updated means different versions of the container being uploaded), and how many people have starred it. It is usually a good rule of thumb to use the most popular containers from users that have uploaded a lot of containers. The biocontainers and pegi3s profiles have builds for a lot of tools, and they are built really well!\nIf we click on the image from biocontainers we get to a typical dockerhub image landing page: \nThere is information on the frequency of the container being pulled, as well as a pull command. This command is for docker, so we need to modify it for Apptainer.\napptainer pull vcftools_0.1.16-1.sif docker://biocontainers/vcftools\nThis command has several parts to it: 1. apptainer calls on the Apptainer software to run 2. pull tells Apptainer which function to use. In this case, we want it to go fetch something from a repository 3. vcftools_0.1.16-1.sif is the name of the container on our local machine. We could call it I_Love_Dogs but that is not very informative at all. Your collaborator won’t know what it means, and you certainly won’t know what it means in 6 months from now! It is also good practice to put the version number in your image name in case you want to have several versions at the same time, and you need to tell them apart. 4. docker:// is the registry you are pulling from. There are several different registreis, but we are only going to show 2 during this course. (You will see another one in the Seqera tutorial) 5. biocontainers/vcftools is the profile/repository and container you are pulling\n\n\n\n\n\n\nTip\n\n\n\n\n\nFile format extensions like .txt and .sif are really only important for us. However, it is good practice to append your files with appropriate extensions to ensure that you follow good data management practices\n\n\n\nIf you are interested in a different version than the current version, there are other versions under the tags tab:\n\n\n\nFilesystem\n\n\nIf you wanted to download another version of the container, you simply copy the command shown on the right side, and alter the syntax, for example\napptainer pull vcftools0.1.14.sif docker://biocontainers/vcftools:v0.1.14_cv2\n\n\nSeqera Tutorial\nThe Seqera landing page is a bit different from the dockerhub landing page, and it works a bit differently from dockerhub. dockerhub hosts container images that users have uploaded, while Seqera builds containers as you request them. They use bioconda, conda-forge, and pypi libraries to build their containers with Wave. The advantage is that you can include several different softwares in your container image at once. The disadvantage is that you are limited to software hosted on the aforementioned repositories. Usually this isn’t a problem, but sometimes you want to use something that isn’t hosted there.\n\n\n\nFilesystem\n\n\nWhen you pull an image from Seqera and want to run it with Apptainer, you need to remember to change the container setting from Docker to Singularity\n\n\n\nFilesystem\n\n\nSince Seqera builds containers on-demand, sometimes you have to wait for the container to finish compiling. You can see that it is still building the container from the fetching container comment. Don’t try to pull it when it is still building!\n\n\n\nFilesystem\n\n\nWhen the container is built, you can copy the text and pull the container to your system\n\n\n\nFilesystem\n\n\napptainer pull vcftools_0.1.17.sif oras://community.wave.seqera.io/library/vcftools:0.1.17--b541aa8d9f9213f9\nHere we use oras:// instead of docker:// as we are pulling from the oras registry. We are also pulling a different version from Seqera, so the name of the container is different.\n\n\n\nRunning Containers\nOnce you have the container on your local machine, you want to be able to use it. Apptainer can be used to enter the container and run as if you had the exact same operating system as the person who built it, or it can run the software inside the container from outside of the container.\nThere are 2 different ways to use a container: run and exec. The apptainer run command launches the container and first runs the %runscript for the container if one is defined, and then runs your command (we will cover %runscript in the Building Containers section). The apptainer exec command will not run the %runscript even if one is defined. It is a small, fiddly detail that might be applicable if you use other people’s containers. After calling Apptainer and the run or exec commands, you can use your software as you usually would\napptainer exec vcftools_0.1.17.sif vcftools --version\nThis command runs your vcftools_0.1.17.sif container, calls on the program vcftools that is within the container, and will show you the version. If you had installed VCFtools locally, you would have just used\nvcftools --version\n\n\nBuilding Containers\nIf the software you would like to use is not packaged into a container by anyone else, you might want to build it yourself. For this, we are just going to show a very simple example. Building containers from scratch is a computationally intensive task. You build containers from a definition file with the extension .def\nHere we are going to build a container with a cow telling us the date. Save this in a file called lolcow.def\nBootstrap: docker\nFrom: ubuntu:20.04\n\n%post\n    apt-get -y update\n    apt-get -y install cowsay lolcat fortune\n\n%environment\n    export LC_ALL=C\n    export PATH=/usr/games:$PATH\n\n%runscript\n    date | cowsay | lolcat    \n\nThere are several components to this definition file. 1. You can set the operating system you want in the container, in this case Ubuntu 20.04 2. %post section is where you update the OS from its base state, install dependencies and so on 3. %environment is where you export paths and modify the environment 4. %runscript is the script that will run when you use apptainer run container.sif. If you don’t include a runscript, then nothing will happen when you try to run it without any commands. You could build this container without anything in the %runscript section, and use apptainer run container.sif date | cowsay | lolcat to get the same output.\napptainer build lolcow.sif lolcow.def\nYou’ll get a lot of output on the status of the build, ending of\nINFO:    Adding environment to container\nINFO:    Adding runscript\nINFO:    Creating SIF file...\nINFO:    Build complete: lolcow.sif\nWe can now run our new container with\napptainer run lolcow.sif\n\n\n\nFilesystem\n\n\n\n\n\n\n\n\nNote\n\n\n\nTry removing the %runscript, build it again, and see what happens\n\n\nBootstrap: docker\nFrom: ubuntu:20.04\n\n%post\n    apt-get -y update\n    apt-get -y install cowsay lolcat fortune\n\n%environment\n    export LC_ALL=C\n    export PATH=/usr/games:$PATH\n\n%runscript\n    fortune | cowsay | lolcat    \n\nIf we use the same definition file as before, but substitute date for fortune in the runscript and build the container, we now get a philosophical cow with a dark sense of humour  \nTo show the difference between the run and exec commands, we can use the same container with fortune in the runscript and run\napptainer run lolcow.sif date|cowsay\nand\napptainer exec lolcow.sif date|cowsay\nThe run command gives us a philosophical cow while exec gives us our boring cow again",
    "crumbs": [
      "Home",
      "Background knowledge with a bit of hands-on",
      "Containers"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This course is a hosted by the Swedish Agricultural University’s Bioinformatics Infrastructure (SLUBI) team. In this course we hope to give you information on how to use reproducible bioinformatics pipelines, report results in a streamlined manner, and implement the system in your own research groups.\nThis course is funded by SIDA and is hosted in Alnarp, Sweden on the 25th-29th August 2025"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SLUBI SIDA Course",
    "section": "",
    "text": "We are pleased to have this course with you! Our main aim with this course is to share how we use bioinformatics tools in a reproducible and scalable way. We will showcase the use of environments, containers, and established pipelines so that you can run these analyses on any operating system, as well as on systems that are not high performance computing clusters.\nThe website will remain active after the course so that you have access to the material, and we encourage you to share these resources with your students and other researchers that might benefit from this!\n\nProgram\n\n\nDay\nSession\n\n\n\n\nMonday\nIntroduction to nf-core and Nextflow\n\n\n\nIntroduction to Linux\n\n\n\nIntroduction to Environments\n\n\nTuesday\nIntroduction to Containers\n\n\n\nSetting up and running a Nextflow Pipeline (with us)\n\n\n\nSetting up and running a Nextflow Pipeline (by yourself)\n\n\nWednesday\nData Management and Reproducible Research\n\n\n\nIntroduction to Markdown and Quarto\n\n\n\nGitHub\n\n\n\nHow do Nextflow Pipelines Work?\n\n\nThursday\nNextflow Results\n\n\n\nUsing Containers Outside of Nextflow\n\n\n\nUsing R and Other Languages in Quarto\n\n\nFriday\nWhat are your needs? How can you implement this in your own institutions?\n\n\n\nFriday is an emptier day in case we run out of time for something, or if there is something that you would like to learn more about.\nEvery day will end with a feedback session, and we hope that you will tell us what you like, what isn’t working for you, and what you would like to see more of.",
    "crumbs": [
      "Home"
    ]
  }
]